{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HackerNews Challenge.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "sjNwxmtv1HAR",
        "zWYfrhr71HAw"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "PxrYAn5A1G-r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# HackerNews data analysis challenge with Spark"
      ]
    },
    {
      "metadata": {
        "id": "wbYXKVsX1G-s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this notebook, you will analyse a dataset of (almost) all submitted HackerNews posts with Spark. Let's start by importing some of the libraries you will need."
      ]
    },
    {
      "metadata": {
        "id": "_MbSJZpc1MPn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www-us.apache.org/dist/spark/spark-2.3.1/spark-2.3.1-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.3.1-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "!wget -q http://188.165.231.140/pub/bigdata-spark/raw/master/war-and-peace.txt\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.3.1-bin-hadoop2.7\"\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark import SparkContext\n",
        "\n",
        "sc = SparkContext.getOrCreate()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Dq4wwNr_1G-t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime as dt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f4rns8LX1G-x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "cd4dfb64-201d-4024-b5c1-b56bf070291b"
      },
      "cell_type": "code",
      "source": [
        "from pyspark import SparkContext\n",
        "sc = SparkContext.getOrCreate()\n",
        "print(sc)\n",
        "print(\"Ready to go!\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<SparkContext master=local[*] appName=pyspark-shell>\n",
            "Ready to go!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DKojEjAB1G-1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The file has one JSON entry per line. In order to make accessing it easier, first turn each entry as a dictionary and use `persist()` to cache the resulting RDD."
      ]
    },
    {
      "metadata": {
        "id": "XHdhPUzO1G-2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5d6275f3-b8ba-4dba-c644-a7d0107eae9d"
      },
      "cell_type": "code",
      "source": [
        "dataset_json = sc.textFile(\"HNStories.json\")\n",
        "dataset = dataset_json.map(lambda x: json.loads(x))\n",
        "dataset.persist()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PythonRDD[12] at RDD at PythonRDD.scala:49"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "tvVqSyGK1G-7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Finally, Spark has many helper functions on top of the ones we have studied which you will find useful. You can view them at [http://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD](http://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD)"
      ]
    },
    {
      "metadata": {
        "id": "FJJjh-Qw1G-9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Task 1"
      ]
    },
    {
      "metadata": {
        "id": "NPH72tZy1G-9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Lets start with some initial analysis. \n",
        "* How many elements are in your datasets?\n",
        "* What does the first element look like?"
      ]
    },
    {
      "metadata": {
        "id": "JCJT_N2E1G-_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "5e644d2b-6e37-4ecd-fe20-ed3a8ec92d96"
      },
      "cell_type": "code",
      "source": [
        "dataset.take(2)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'author': 'TuxLyn',\n",
              "  'created_at': '2014-05-29T08:25:40Z',\n",
              "  'created_at_i': 1401351940,\n",
              "  'num_comments': 0,\n",
              "  'objectID': '7815290',\n",
              "  'points': 1,\n",
              "  'title': 'DuckDuckGo Settings',\n",
              "  'url': 'https://duckduckgo.com/settings'},\n",
              " {'author': 'Leynos',\n",
              "  'created_at': '2014-05-29T08:23:46Z',\n",
              "  'created_at_i': 1401351826,\n",
              "  'num_comments': 0,\n",
              "  'objectID': '7815285',\n",
              "  'points': 1,\n",
              "  'title': 'Making Twitter Easier to Use',\n",
              "  'url': 'http://bits.blogs.nytimes.com/2014/05/28/making-twitter-easier-to-use/'}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "metadata": {
        "id": "RPSiHqOuEoXe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8374434d-f755-4f67-8100-14f126cd136c"
      },
      "cell_type": "code",
      "source": [
        "dataset.count()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1329479"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "dgO9oVm_1G_F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Each element is a dictionary of attributes and their values for a post. Can you find the set of all attributes used throughout the RDD? The function `dictionary.keys()` gives you the list of attributes of a dictionary."
      ]
    },
    {
      "metadata": {
        "id": "iVbn8-qq1G_H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wWt5cOIq1G_L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We see that there are more attributes than just the one used in the first element. the function `compare_elems` below returns `True` if two elements have exactly the same set of attributes. Can you use it to count the number of elements which have the same set of attributes as the first element?"
      ]
    },
    {
      "metadata": {
        "id": "kzk7LVC91G_L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Returns true if two elements have the same schema\n",
        "def compare_elems(first, second):\n",
        "    if len(first) != len(second):\n",
        "        return False\n",
        "    for key in first.keys():\n",
        "        if key not in second:\n",
        "            return False\n",
        "    return True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K5GxTLT71G_P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d9b50878-2a45-47d1-8702-3c3740b3ce3b"
      },
      "cell_type": "code",
      "source": [
        "first =  dataset.take(1)[0]\n",
        "dataset.filter(lambda x: compare_elems(first,x)).count()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1141437"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "metadata": {
        "id": "v_MGR3am1G_S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We see that the vast majority of elements hold the same structure. In order to make this analysis easier, redefine `dataset` to only have elements which hold this structure."
      ]
    },
    {
      "metadata": {
        "id": "NqN3gi_X1G_T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IoCPK3yX1G_W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "All of the following tasks are optional, if you want to analyse the dataset in your own way using Spark feel free to do so! The tasks are there as a guide."
      ]
    },
    {
      "metadata": {
        "id": "pBha1zFx1G_X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Task 2: How many posts through time"
      ]
    },
    {
      "metadata": {
        "id": "WrYeZy8p1G_Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The field `created_at_i` is very useful, it gives you a UNIX timestamp of the time at which the file was created. The following function lets you extract a time from a timestamp."
      ]
    },
    {
      "metadata": {
        "id": "j2lnPIp_1G_Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def extract_time(timestamp):\n",
        "    return dt.fromtimestamp(timestamp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "51TWiiX71G_d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Find the minimum and maximum timestamps in the RDD and call them `min_time` and `max_time`. These correspond to the first and last post, when did they occur?"
      ]
    },
    {
      "metadata": {
        "id": "1eEOKDIj1G_e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "l=dataset.keys()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tl2HeNsO1G_k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OU5vWbqS1G_n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "g0xQP9381G_q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(min_time)\n",
        "print(max_time)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N3_lB9_U1G_t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now lets analyse how many elements through time. The following function assigns a record to one of 200 \"buckets\" of time. Use it to count the number of elements that fall within each bucket and call the result `bucket_rdd`. The result should be such that `buckets` below generates the corresponding output."
      ]
    },
    {
      "metadata": {
        "id": "B3XoaDFk1G_u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "interval = (max_time - min_time + 1) / 200.0\n",
        "\n",
        "def get_bucket(rec):\n",
        "    return int((rec['created_at_i'] - min_time) / interval)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "weD_pWEE1G_w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5sRmMx0l1G_z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Use this to test your result\n",
        "buckets = sorted(buckets_rdd.collect())\n",
        "print(buckets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AZ_sLY6d1G_4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This is approximately the desired output\n",
        "buckets = sorted(buckets_rdd.collect())\n",
        "print(buckets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Hs8UDPGu1G_7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can then use this to plot the number of submitted posts over time."
      ]
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "09RKMLNG1G_9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bs = [dt.fromtimestamp(x[0]*interval + min_time) for x in buckets]\n",
        "ts = [x[1] for x in buckets]\n",
        "plt.plot(bs, ts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L9HBmPkB1G__",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Task 3"
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "snWltpaU1HAA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The following function gets the hour of the day at which a post was submitted. Use it to find the number of posts submitted at each hour of the day. The value of `hours_buckets` should match the one printed below."
      ]
    },
    {
      "metadata": {
        "id": "tqmzzJfJ1HAB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_hour(rec):\n",
        "    t = dt.fromtimestamp(rec['created_at_i'])\n",
        "    return t.hour"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4mDqpTB21HAE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "hours = dataset.map(lambda x: get_hour(x))\n",
        "hours_tuples = hours.map(lambda x:(x,1))\n",
        "add = hours_tuples.reduceByKey(lambda a, b:(a+b))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VEFoazlfJxGk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c5b08e29-740b-487a-a449-60d93de6c446"
      },
      "cell_type": "code",
      "source": [
        "hours.take(5)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[8, 8, 8, 8, 8]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "metadata": {
        "id": "rpghAx0Z1HAH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "27fd1e27-76fc-4fab-a054-c96995f1d31c"
      },
      "cell_type": "code",
      "source": [
        "hours_buckets = sorted(add.collect())\n",
        "print(hours_buckets)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, 43671), (1, 42207), (2, 41010), (3, 40268), (4, 39084), (5, 38974), (6, 39532), (7, 38527), (8, 38015), (9, 39683), (10, 40762), (11, 45826), (12, 54858), (13, 66312), (14, 76720), (15, 82340), (16, 84926), (17, 84396), (18, 80720), (19, 73716), (20, 69156), (21, 64371), (22, 55961), (23, 48444)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XC0l-m4r1HAL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "71fe3d37-bd3e-4cc8-c626-241ff4128a00"
      },
      "cell_type": "code",
      "source": [
        "hours_buckets = sorted(hours_buckets_rdd.collect())\n",
        "print(hours_buckets)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, 43671), (1, 42207), (2, 41010), (3, 40268), (4, 39084), (5, 38974), (6, 39532), (7, 38527), (8, 38015), (9, 39683), (10, 40762), (11, 45826), (12, 54858), (13, 66312), (14, 76720), (15, 82340), (16, 84926), (17, 84396), (18, 80720), (19, 73716), (20, 69156), (21, 64371), (22, 55961), (23, 48444)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "OowvGIrL1HAO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "63369e5e-5405-4dbb-9fd2-e756d7f06c84"
      },
      "cell_type": "code",
      "source": [
        "hrs = [x[0] for x in hours_buckets]\n",
        "sz = [x[1] for x in hours_buckets]\n",
        "plt.plot(hrs, sz)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fbab444c4a8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nvApNqYeatAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fbab4dd4550>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "sjNwxmtv1HAR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Task 4"
      ]
    },
    {
      "metadata": {
        "id": "wQraPRWy1HAS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The number of points scored by a post is under the attribute `points`. Use it to compute the average score received by submissions for each hour."
      ]
    },
    {
      "metadata": {
        "id": "iSdnvUEB1HAU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TrgURj6b1HAX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "scores_per_hour = sorted(scores_per_hour_rdd.collect())\n",
        "print(scores_per_hour)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xJNpvGkz1HAZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "scores_per_hour = sorted(scores_per_hour_rdd.collect())\n",
        "print(scores_per_hour)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vfZXgJp41HAd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "hrs = [x[0] for x in scores_per_hour]\n",
        "sz = [x[1] for x in scores_per_hour]\n",
        "plt.plot(hrs, sz)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "637-Fo2k1HAf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "It may be more useful to look at sucessful posts that get over 200 points. Find the proportion of posts that get above 200 points per hour."
      ]
    },
    {
      "metadata": {
        "id": "mgOPPSmM1HAg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BS0UP1pQ1HAj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "prop_per_hour = sorted(prop_per_hour_rdd.collect())\n",
        "print(prop_per_hour)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZJ2gOJ4W1HAp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "prop_per_hour = sorted(prop_per_hour_rdd.collect())\n",
        "print(prop_per_hour)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AU3_uwDm1HAs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "hrs = [x[0] for x in prop_per_hour]\n",
        "sz = [x[1] for x in prop_per_hour]\n",
        "plt.plot(hrs, sz)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zWYfrhr71HAw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Task 5"
      ]
    },
    {
      "metadata": {
        "id": "0U45odaw1HAw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The following function lists the word in the title. Use it to count the number of words in the title of each post, and look at the proportion of successful posts for each title length."
      ]
    },
    {
      "metadata": {
        "id": "k3By0QfF1HAx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "def get_words(line):\n",
        "    return re.compile('\\w+').findall(line)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DAatEqEzNXm6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a38d1f2f-a654-44e7-a411-dbf80be56279"
      },
      "cell_type": "code",
      "source": [
        "l=get_words('lucky girl')\n",
        "print(l)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['lucky', 'girl']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oHzY99DY1HA1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cnt = dataset.map(lambda x: get_words(x['title']))\n",
        "leng= cnt.map(lambda x: len(x))\n",
        "red = leng.map(lambda x:(x,1))\n",
        "grp = red.reduceByKey(lambda a, b:a+b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rs9YPIhjMoSJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3302
        },
        "outputId": "cf66fa73-84cd-45bf-d68d-07a636b90993"
      },
      "cell_type": "code",
      "source": [
        "red.count()"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Py4JJavaError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-958d18a4350a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/spark-2.3.1-bin-hadoop2.7/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mcount\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1071\u001b[0m         \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m         \"\"\"\n\u001b[0;32m-> 1073\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-2.3.1-bin-hadoop2.7/python/pyspark/rdd.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1062\u001b[0m         \u001b[0;36m6.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m         \"\"\"\n\u001b[0;32m-> 1064\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-2.3.1-bin-hadoop2.7/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mfold\u001b[0;34m(self, zeroValue, op)\u001b[0m\n\u001b[1;32m    933\u001b[0m         \u001b[0;31m# zeroValue provided to each partition is unique from the one provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m         \u001b[0;31m# to the final reduce call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m         \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzeroValue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-2.3.1-bin-hadoop2.7/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    832\u001b[0m         \"\"\"\n\u001b[1;32m    833\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectAndServe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    835\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-2.3.1-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-2.3.1-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 54.0 failed 1 times, most recent failure: Lost task 1.0 in stage 54.0 (TID 173, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/content/spark-2.3.1-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 230, in main\n    process()\n  File \"/content/spark-2.3.1-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 225, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/content/spark-2.3.1-bin-hadoop2.7/python/pyspark/rdd.py\", line 2457, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/content/spark-2.3.1-bin-hadoop2.7/python/pyspark/rdd.py\", line 2457, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/content/spark-2.3.1-bin-hadoop2.7/python/pyspark/rdd.py\", line 2457, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/content/spark-2.3.1-bin-hadoop2.7/python/pyspark/rdd.py\", line 370, in func\n    return f(iterator)\n  File \"/content/spark-2.3.1-bin-hadoop2.7/python/pyspark/rdd.py\", line 1073, in <lambda>\n    return self.mapPartitions(lambda i: [sum(1 for _ in i)]).sum()\n  File \"/content/spark-2.3.1-bin-hadoop2.7/python/pyspark/rdd.py\", line 1073, in <genexpr>\n    return self.mapPartitions(lambda i: [sum(1 for _ in i)]).sum()\n  File \"/content/spark-2.3.1-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/util.py\", line 55, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-97-4f989b5d8ff1>\", line 1, in <lambda>\nKeyError: 'title'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:298)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:438)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:421)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:252)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2074)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2074)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1602)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1590)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1589)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1589)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1823)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1772)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1761)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:939)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:938)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:162)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/content/spark-2.3.1-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 230, in main\n    process()\n  File \"/content/spark-2.3.1-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 225, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/content/spark-2.3.1-bin-hadoop2.7/python/pyspark/rdd.py\", line 2457, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/content/spark-2.3.1-bin-hadoop2.7/python/pyspark/rdd.py\", line 2457, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/content/spark-2.3.1-bin-hadoop2.7/python/pyspark/rdd.py\", line 2457, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/content/spark-2.3.1-bin-hadoop2.7/python/pyspark/rdd.py\", line 370, in func\n    return f(iterator)\n  File \"/content/spark-2.3.1-bin-hadoop2.7/python/pyspark/rdd.py\", line 1073, in <lambda>\n    return self.mapPartitions(lambda i: [sum(1 for _ in i)]).sum()\n  File \"/content/spark-2.3.1-bin-hadoop2.7/python/pyspark/rdd.py\", line 1073, in <genexpr>\n    return self.mapPartitions(lambda i: [sum(1 for _ in i)]).sum()\n  File \"/content/spark-2.3.1-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/util.py\", line 55, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-97-4f989b5d8ff1>\", line 1, in <lambda>\nKeyError: 'title'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:298)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:438)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:421)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:252)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2074)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2074)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "X6lE9mqJ1HA2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "outputId": "6d1ac4a6-20db-48fc-c9f3-e71900711466"
      },
      "cell_type": "code",
      "source": [
        "s+prop_per_title_length = sorted(grp.collect())\n",
        "print(prop_per_title_length)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-93-ec8555292ded>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    s+prop_per_title_length = sorted(grp.collect())\u001b[0m\n\u001b[0m                                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m can't assign to operator\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "JPAml-1v1HA5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "8421cde6-d9af-41a9-e48b-a27f7904da98"
      },
      "cell_type": "code",
      "source": [
        "prop_per_title_length = sorted(prop_per_title_length_rdd.collect())\n",
        "print(prop_per_title_length)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-94-77cbc93c1cc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprop_per_title_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprop_per_title_length_rdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprop_per_title_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'prop_per_title_length_rdd' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "rflLcgGO1HA7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "ee55b1ff-9a43-416c-e73c-a0d4e7c72de6"
      },
      "cell_type": "code",
      "source": [
        "hrs = [x[0] for x in prop_per_title_length]\n",
        "sz = [x[1] for x in prop_per_title_length]\n",
        "plt.plot(hrs, sz)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-95-5240841a163a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprop_per_title_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprop_per_title_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'prop_per_title_length' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "BH1P74jE1HA-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Lets compare this with the distribution of number of words. Count for each title length the number of submissions with that length."
      ]
    },
    {
      "metadata": {
        "id": "C2jv3QWb1HA-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jTWWn0WW1HBA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "submissions_per_length = sorted(submissions_per_length_rdd.collect())\n",
        "print(submissions_per_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "46nOBWeL1HBC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "submissions_per_length = sorted(submissions_per_length_rdd.collect())\n",
        "print(submissions_per_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DSbgrcFG1HBF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "hrs = [x[0] for x in submissions_per_length]\n",
        "sz = [x[1] for x in submissions_per_length]\n",
        "plt.plot(hrs, sz)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6EmkCPbv1HBJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Looks like most people are getting it wrong!"
      ]
    },
    {
      "metadata": {
        "id": "Weyg1sm51HBK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Task 6"
      ]
    },
    {
      "metadata": {
        "id": "VS4LbSec8mFg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ]
    },
    {
      "metadata": {
        "id": "TfHG22Ut8m33",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "VA3pDg8V1HBL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For this task, you will need a new function: `takeOrdered()`. Like `take()` it collects elements from an RDD. However, it can be applied the smalles elements. For example, `takeOrdered(10)` returns the 10 smallest elements. Furthermore, you can pass it a function to specify the way in which the elements should be ordered. For example, `takeOrdered(10, lambda x: -x)` will return the 10 largest elements.\n",
        "\n",
        "The function below extracts the url domain out of a record. Use it to count the number of distinct domains posted to."
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "s3aaOsFB1HBN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from urlparse import urlparse\n",
        "def get_domain(rec):\n",
        "    url = urlparse(rec['url']).netloc\n",
        "    if url[0:4] == 'www.':\n",
        "        return url[4:]\n",
        "    else:\n",
        "        return url\n",
        "print(get_domain(dataset.take(1)[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3MfSgHC31HBQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lsu51AqO1HBS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Using `takeOrdered()` find the 25 most popular domains posted to."
      ]
    },
    {
      "metadata": {
        "id": "so_BZQAz1HBT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1TRNWIQa1HBW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(top25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vr2ZBz7O1HBa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(top25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kQonwErE1HBc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "index = np.arange(25)\n",
        "labels = [x[0] for x in top25]\n",
        "counts = np.array([x[1] for x in top25]) * 100.0/dataset.count()\n",
        "plt.xticks(index,labels, rotation='vertical')\n",
        "plt.bar(index, counts, 0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-qeM_sDP1HBe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create an pair RDD with 26 elements mapping each of these 25 popular domains with the average score received by the corresponding submissions as well as an `other` field for all submissions to other domains."
      ]
    },
    {
      "metadata": {
        "id": "2VAJBiFe1HBf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def map_to_domain(rec):\n",
        "    domain = get_domain(rec)\n",
        "    if domain in dict(top25):\n",
        "        return domain\n",
        "    else:\n",
        "        return 'other'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "clFRrLxS1HBi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NBtrcx-31HBl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "domain_av_score = domain_av_score_rdd.collect()\n",
        "print(domain_av_score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h1mQne2Q1HBn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "domain_av_score = domain_av_score_rdd.collect()\n",
        "print(domain_av_score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jIy40lBG1HBq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "index26 = np.arange(26)\n",
        "labels = [x[0] for x in top25]\n",
        "labels.append('other')\n",
        "vals = np.array([dict(domain_av_score)[x] for x in labels])\n",
        "plt.xticks(index26, labels, rotation='vertical')\n",
        "plt.bar(index26, vals, 0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ro50l9nS1HBs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now compute the proportion of successes for each domain (over 200 points)."
      ]
    },
    {
      "metadata": {
        "id": "pyN0wneR1HBs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kw0fLezJ1HBt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "domain_prop = domain_prop_rdd.collect()\n",
        "print(domain_prop)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "stTa3fTU1HBv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "domain_prop = domain_prop_rdd.collect()\n",
        "print(domain_prop)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8-LQmxfy1HBy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "index26 = np.arange(26)\n",
        "labels = [x[0] for x in top25]\n",
        "labels.append('other')\n",
        "vals = np.array([dict(domain_prop)[x] for x in labels])\n",
        "plt.xticks(index26, labels, rotation='vertical')\n",
        "plt.bar(index26, vals, 0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}